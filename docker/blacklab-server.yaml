---
    # BlackLab Server config file
    # ===============================================================
    # NOTE: this file is in JSON format, with end-of-line comments (#) allowed.
    
    
    # The location and parameters for each index
    # ---------------------------------------------------------------
    # (missing indices will be skipped)
    
    # Index collections are multiple indices under a single directory.
    # BLS will detect when an index is added and make it available to
    # query. It will also detect if it is removed.
    # NOTE: if multiple accessible collections contain indices with the 
    # same name, one of them is picked at random (i.e. don't do this).  
    indexCollections:
    - /data/
    
    # Settings related to debugging and troubleshooting
    debug:
      # A list of IPs that will run in debug mode.
      # In debug mode, ...
      # - the /cache-info resource show the contents of the job cache
      #   (other debug information resources may be added in the 
      #   future)
      # - output is prettyprinted by default (can be overriden with the
      #   "prettyprint"
      #   GET parameter)
      addresses:
      - 127.0.0.1
      - '0:0:0:0:0:0:0:1'

      # Should all private addresses run in debug mode? (default: no)
      # Useful for development using Docker containers. Disable in production.
      # (e.g. 10.*, 172.(16-31).*, 192.168.*)
      allPrivateAddressesAsDebug: yes
    
    
    # Settings related to tuning server load and client responsiveness
    # ---------------------------------------------------------------
    performance:
    
      # Settings for controlling server load
      serverLoad:
    
        # Maximum number of concurrent searches.
        # Should be set no higher than the number of cores in the machine. 
        maxConcurrentSearches: 6

      # The minimum amount of free memory required to start a new search job. If this memory is not available,
      # an error message is returned.
      minFreeMemForSearchMegs: 30
    
      # The maximum number of jobs a user is allowed to have running at the same time. This does not
      # include finished jobs in the cache, only jobs that have not finished yet.
      # The above remark about jobs applies here too: one search request will start multiple jobs.
      # Therefore, this value shouldn't be set too low. This setting is meant to prevent over-eager scripts 
      # and other abuse from bringing down the server. Regular users should never hit this limit.
      maxRunningJobsPerUser: 10
    
      # How long the client may keep results we give them in their local (browser) cache.
      # This is used to write HTTP cache headers. Low values mean clients might re-request
      # the same information, making clients less responsive and consuming more network resources.
      # Higher values make clients more responsive but could cause problems if the data (or worse,
      # the protocol) changes after an update. A value of an hour or so seems reasonable.
      clientCacheTimeSec: 3600
